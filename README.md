# Processo Trainee - IEEE CIS Chapter Universidade de BrasÃ­lia ğŸš€

Somos um capÃ­tulo estudantil vinculado Ã  IEEE, a maior organizaÃ§Ã£o profissional do mundo dedicada ao avanÃ§o da tecnologia em benefÃ­cio da humanidade. Nosso objetivo Ã© capacitar estudantes na Ã¡rea de inteligÃªncia computacional e inteligÃªncia artificial e democratizar o conhecimento. ğŸ¯

Sejam bem vindos, aqui estarÃ£o presentes todos os arquivos referentes aos perÃ­odos do processo Trainee do CIS!

---
# SumÃ¡rio


- [1Âº PerÃ­odo â€” RegressÃ£o e ClassificaÃ§Ã£o](#1o-periodo-regressao-e-classificacao-0505--1205)  
- [2Âº PerÃ­odo â€” ClusterizaÃ§Ã£o](#2o-periodo-clusterizacao-1205--1905)  
- [3Âº PerÃ­odo â€” Redes Neurais](#3o-periodo-redes-neurais)  
- [4Âº PerÃ­odo â€” VisÃ£o Computacional](#4o-periodo-visao-computacional-0306--1006)  
- [5Âº PerÃ­odo â€” ApresentaÃ§Ãµes](#5o-periodo-apresentacoes-0206--0906)

---

<!-- 1Âº PerÃ­odo -->
# ğŸ“… 1 PerÃ­odo â€” RegressÃ£o e ClassificaÃ§Ã£o (05/05 â€“ 12/05)

## ğŸ“Œ RegressÃ£o Linear
- **Objetivo:** prever valores contÃ­nuos.
- **MSE** ğŸŸ¦: erro mÃ©dio ao quadrado, sensÃ­vel a outliers.
- **MAE** ğŸŸ©: erro mÃ©dio absoluto, menos sensÃ­vel a outliers.
- **Uso:** MSE penaliza mais erros grandes; MAE mostra erro mÃ©dio real.

## ğŸ“Œ ClassificaÃ§Ã£o
- **DefiniÃ§Ã£o:** prever categorias a partir de dados.
- **Exemplo:** e-mails *spam* ou *nÃ£o spam*.
- **Lazy Learners** ğŸ¢: memorizam dados; adaptaÃ§Ã£o rÃ¡pida; prediÃ§Ã£o lenta.
- **Eager Learners** ğŸš€: criam modelo; prediÃ§Ã£o rÃ¡pida; menos adaptÃ¡veis.

## ğŸ“Œ MÃ©tricas de ClassificaÃ§Ã£o
- **AcurÃ¡cia** ğŸ“Š: % de acertos (bom p/ dados balanceados).
- **PrecisÃ£o** ğŸ¯: positivos corretos / previstos positivos.
- **Recall** ğŸ”: positivos encontrados / positivos reais.
- **F1-score** âš–ï¸: equilÃ­brio entre precisÃ£o e recall.

### ğŸ“‚ Aula
- [Slides](1_PerÃ­odo/Apresentacao.pdf)

#### ğŸ“ Desafio de RegressÃ£o â€” Wine Quality  
- **Objetivo:** Criar um modelo de regressÃ£o para prever a qualidade do vinho verde (variedade vermelha ou branca) com base em dados quÃ­micos (ex.: acidez, pH, Ã¡lcool).  
- **Dados:** 11 atributos quÃ­micos; variÃ¡vel alvo: qualidade (score 0-10).  
- **Entrega:** Individual, no GitHub pessoal.  
- [Atividade Completa](1_PerÃ­odo/Atividade_regrecao.pdf)

---

#### ğŸ“ Desafio de ClassificaÃ§Ã£o â€” Census Income  
- **Objetivo:** Construir modelos de classificaÃ§Ã£o binÃ¡ria para prever se a renda anual de um indivÃ­duo Ã© maior que US$ 50.000.  
- **Dados:** 48.842 registros com 14 atributos demogrÃ¡ficos e socioeconÃ´micos (idade, educaÃ§Ã£o, ocupaÃ§Ã£o, etc.).  
- **Tarefas obrigatÃ³rias:** Treinar Ãrvore de DecisÃ£o e Random Forest; avaliar com acurÃ¡cia, precisÃ£o, recall e F1; gerar matriz de confusÃ£o e grÃ¡fico de importÃ¢ncia.  
- **Tarefas opcionais:** AnÃ¡lise exploratÃ³ria, validaÃ§Ã£o cruzada e reduÃ§Ã£o de dimensionalidade.  
- [Atividade Completa](1_PerÃ­odo/Atividade_classificacao.pdf)
---

<!-- 2  PerÃ­odo -->
# ğŸ“… 2o Periodo - Clusterizacao (12/05 â€“ 19/05)

### ğŸ“Œ Aprendizado Supervisionado vs. NÃ£o Supervisionado

- **Supervisionado:** Prever classe (classificaÃ§Ã£o) ou valor contÃ­nuo (regressÃ£o) usando dados rotulados.  
- **NÃ£o Supervisionado:** Descobrir padrÃµes e agrupar dados nÃ£o rotulados, como em clusterizaÃ§Ã£o.

---

### ğŸ“Œ O que Ã© ClusterizaÃ§Ã£o?

- TÃ©cnica de aprendizado **nÃ£o supervisionado** que agrupa dados semelhantes em **clusters**.  
- ğŸ¯ **Objetivo:** Maximizar a similaridade dentro dos grupos e minimizar entre grupos diferentes.

---

### ğŸ“Œ Por que usar ClusterizaÃ§Ã£o?

- ğŸ” IdentificaÃ§Ã£o automÃ¡tica de padrÃµes sem necessidade de supervisÃ£o.  
- ğŸ“‰ ReduÃ§Ã£o de dimensionalidade e simplificaÃ§Ã£o dos dados.  
- ğŸ§© Auxilia na tomada de decisÃ£o baseada em agrupamentos.

---

### ğŸ“Œ Funcionamento do K-means

1. ğŸš€ **InicializaÃ§Ã£o:** Escolha K centrÃ³ides aleatÃ³rios.  
2. ğŸ¯ **AtribuiÃ§Ã£o:** Associe cada ponto ao centrÃ³ide mais prÃ³ximo.  
3. ğŸ”„ **Recalcular centrÃ³ides:** MÃ©dia dos pontos em cada grupo.  
4. ğŸ” **Repetir:** AtÃ© os centrÃ³ides nÃ£o mudarem (convergÃªncia).

---

### ğŸ“Œ Outros pontos Importantes

- ğŸ“Š **InÃ©rcia:** Mede a qualidade dos clusters; valores menores indicam clusters mais compactos.  
- ğŸ”¢ **NÃºmero ideal de clusters:** Determinado por anÃ¡lise da inÃ©rcia ou mÃ©todos especÃ­ficos.  
- âš™ï¸ Existem outros modelos de clusterizaÃ§Ã£o alÃ©m do K-means.

---

### ğŸ“š Aula
- [Slides do Segundo PerÃ­odo](2_PerÃ­odo/Apresentacao.pdf)

### ğŸ“ Desafio â€” 2Âº PerÃ­odo: ClusterizaÃ§Ã£o

- ğŸš€ Implementar K-Means do zero em Python.  
- ğŸ“Š Analisar *Student Habits vs Academic Performance*: levantar hipÃ³teses, fazer EDA e revisar com resultados.  
- ğŸ”¢ Justificar o nÃºmero de clusters (K).  
- ğŸ“š Opcional: pesquisar DBSCAN, Hierarchical Clustering e algoritmo avanÃ§ado.

> ğŸ’¡ *Dica:* â€œSe vocÃª torturar os dados por tempo suficiente, eles confessarÃ£o.â€  
- [Desafio de ClusterizaÃ§Ã£o](2_PerÃ­odo/Atividade.pdf)

--- 
<!-- 3  PerÃ­odo -->
# ğŸ“… 3Âº PerÃ­odo â€” Redes Neurais

### ğŸ“Œ O que sÃ£o Redes Neurais?

- Inspiradas no cÃ©rebro humano para aprender padrÃµes complexos.  
- Usadas em reconhecimento de imagem, traduÃ§Ã£o, previsÃ£o, entre outros.  
- NÃ£o "pensam", mas capturam relaÃ§Ãµes complexas nos dados.

---

### ğŸ“Œ ConteÃºdos Principais

- Perceptron, funÃ§Ãµes de ativaÃ§Ã£o, pesos e bias.  
- Feedforward, backpropagation e gradiente descendente.  
- FunÃ§Ã£o de custo, mÃ©tricas de avaliaÃ§Ã£o.  
- Overfitting, underfitting, regularizaÃ§Ã£o e otimizaÃ§Ã£o.  
- ImplementaÃ§Ã£o prÃ¡tica com TensorFlow e PyTorch.

---

### ğŸ“Œ Base de Dados

- Stellar Classification Dataset (galÃ¡xias, quasares e estrelas) do Kaggle.

---

### ğŸ“ Desafio â€” 3Âº PerÃ­odo: Redes Neurais

- ğŸ› ï¸ Construir uma rede neural para classificar galÃ¡xias, quasares e estrelas.  
- âš™ï¸ Testar variaÃ§Ãµes na arquitetura, Ã©pocas e learning rate.  
- ğŸ” Identificar overfitting e underfitting, aplicando regularizaÃ§Ã£o.  
- ğŸ’¡ Opcional: criar rede neural â€œfrom scratchâ€ em Python e testar outros datasets via Keras.

---

### ğŸ“š Aula  
- [Slides do Terceiro PerÃ­odo](3_PerÃ­odo/Apresentacao.pdf)

### ğŸ“ Link do Desafio  
- [Desafio de Redes Neurais](3_PerÃ­odo/Atividade.pdf)

--- 
# ğŸ“… 4Âº PerÃ­odo â€” VisÃ£o Computacional (03/06 â€“ 10/06)

### ğŸ“Œ O que sÃ£o Redes Neurais Convolucionais (CNNs)?

- Algoritmos de aprendizado profundo especializados em reconhecimento de objetos.  
- AplicaÃ§Ãµes: classificaÃ§Ã£o de imagens, detecÃ§Ã£o de objetos, segmentaÃ§Ã£o, veÃ­culos autÃ´nomos, sistemas de seguranÃ§a, etc.  
- Inspiradas no cÃ³rtex visual humano, com arquitetura hierÃ¡rquica e conectividade local.  

---

### ğŸ“Œ Componentes Principais das CNNs

1. **Camadas Convolucionais:** Aplicam filtros (kernels) para extrair padrÃµes locais (bordas, formas).  
2. **FunÃ§Ã£o de AtivaÃ§Ã£o (ReLU):** Introduz nÃ£o-linearidade e ajuda a aprender padrÃµes complexos.  
3. **Camadas de Pooling:** Reduzem a dimensionalidade, destacando caracterÃ­sticas importantes e ajudando a evitar overfitting.  
4. **Camadas Totalmente Conectadas:** Realizam a classificaÃ§Ã£o final, geralmente usando Softmax para gerar probabilidades.  

---

### ğŸ“Œ Overfitting e RegularizaÃ§Ã£o

- **Overfitting:** Quando o modelo decora os dados de treino, mas falha em generalizar.  
- **TÃ©cnicas para mitigar:**  
  - Dropout  
  - Batch Normalization  
  - Early Stopping  
  - Data Augmentation  
  - RegularizaÃ§Ã£o L1 e L2  

---

### ğŸ“Œ AplicaÃ§Ãµes PrÃ¡ticas

- ClassificaÃ§Ã£o e organizaÃ§Ã£o automÃ¡tica de imagens.  
- DetecÃ§Ã£o e localizaÃ§Ã£o de objetos em imagens.  
- Reconhecimento facial para seguranÃ§a.  
- VeÃ­culos autÃ´nomos e diagnÃ³stico mÃ©dico.  

---

### ğŸ“Œ Frameworks Populares

- **TensorFlow:** Ferramenta completa para desenvolvimento e deploy.  
- **Keras:** Interface simples para prototipagem rÃ¡pida, roda sobre TensorFlow.  
- **PyTorch:** Popular por seu grafo dinÃ¢mico e uso em pesquisa.  

---

### ğŸ“š Materiais e Recursos

- [Slides Redes Neurais Convolucionais](4_PerÃ­odo/aulÃ£o_cnn.pdf)  
- [Notebook AplicaÃ§Ã£o Multiclasse](4_PerÃ­odo/clouds.ipynb)  
- [Extras sobre UtilizaÃ§Ã£o](4_PerÃ­odo/multiclass.pdf)  
- [Notebook Extras](4_PerÃ­odo/more_examples.ipynb)  

---

### ğŸ“ Desafio â€” 4Âº PerÃ­odo: CNNs

- Implementar e treinar CNN para tarefas de visÃ£o computacional.  
- Explorar camadas convolucionais, pooling, ativaÃ§Ã£o e regularizaÃ§Ã£o.  
- Aplicar tÃ©cnicas para evitar overfitting.  
- Utilizar frameworks como TensorFlow, Keras ou PyTorch.

- [Desafio de Redes Neurais Convolucionais](4_PerÃ­odo/Atividade.pdf)
# ğŸ“… 5Âº PerÃ­odo â€” ApresentaÃ§Ãµes (02/06 â€“ 09/06)

Nesta etapa, os grupos apresentam um modelo de IA, mostrando todo o aprendizado adquirido nos perÃ­odos anteriores. Ã‰ o momento de **compartilhar conhecimento, resultados e experiÃªncias.**


## ğŸ¯ Objetivos das ApresentaÃ§Ãµes

- **Comunicar ideias com clareza:** Explicar conceitos e processos de forma objetiva e compreensÃ­vel.  
- **Demonstrar aplicaÃ§Ãµes prÃ¡ticas:** Mostrar como os modelos estudados podem ser aplicados em situaÃ§Ãµes reais.  
- **Analisar criticamente:** Apontar pontos fortes, limitaÃ§Ãµes e possÃ­veis melhorias do modelo ou abordagem.  
- **Engajar o pÃºblico:** Incentivar perguntas, reflexÃµes e discussÃµes construtivas.  



## ğŸ’¡ ImportÃ¢ncia desta etapa

O 5Âº perÃ­odo Ã© o **clÃ­max do ciclo de aprendizado**, permitindo que cada grupo **sintetize e compartilhe todo o conhecimento adquirido**, alÃ©m de exercitar habilidades essenciais de comunicaÃ§Ã£o, trabalho em equipe e anÃ¡lise crÃ­tica de modelos de InteligÃªncia Artificial e aprendizado de mÃ¡quina.

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsjuXve9eXVLOkuk+sfl3O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Importação das Bibliotecas\n","\n","Nesta célula importamos todas as bibliotecas necessárias para o projeto.\n","\n","- **PyTorch (`torch`, `torch.nn`, `torch.optim`)**: utilizado para criar, treinar e avaliar a rede neural do tipo Variational Autoencoder (VAE).\n","- **Pandas (`pd`)** e **NumPy (`np`)**: usados para manipulação e processamento dos dados.\n","- **Scikit-learn**:\n","  - `train_test_split`: para separar os dados em conjuntos de treino e teste.\n","  - `StandardScaler`: para normalizar as features numéricas.\n","- **Torch Utils (`DataLoader`, `TensorDataset`)**: facilitam o gerenciamento de dados em formato compatível com PyTorch.\n"],"metadata":{"id":"F6hqQuasluct"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"wHj9cYDkgEfy","executionInfo":{"status":"ok","timestamp":1769002543214,"user_tz":180,"elapsed":9715,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","source":["## Carregamento do Dataset\n","\n","Aqui carregamos o dataset **Delaney (ESOL)**, que contém descritores moleculares e informações de solubilidade.\n","\n","Esse dataset é amplamente utilizado em Química Computacional e Drug Discovery para tarefas de:\n","- Predição de propriedades moleculares\n","- Aprendizado de representações químicas\n","\n","## Extração das Features\n","\n","Aqui extraímos do DataFrame apenas as colunas selecionadas anteriormente e as convertemos para um array NumPy.\n","\n","Esse formato é necessário para:\n","- Normalização dos dados\n","- Conversão posterior para tensores PyTorch"],"metadata":{"id":"v2rjOCaAlzKb"}},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/UnB-CIS/UnB-CIS-UEG-MPhysChem/refs/heads/main/4_Dia/delaney-processed.csv\"\n","df = pd.read_csv(url)\n","\n","features = [\n","    \"Minimum Degree\",\n","    \"Molecular Weight\",\n","    \"Number of H-Bond Donors\",\n","    \"Number of Rings\",\n","    \"Number of Rotatable Bonds\",\n","    \"Polar Surface Area\"\n","]\n","\n","X = df[features].values"],"metadata":{"id":"rv1HyUYqgGNW","executionInfo":{"status":"ok","timestamp":1769002543233,"user_tz":180,"elapsed":21,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Normalização das Features\n","\n","Utilizamos o `StandardScaler` para padronizar as features:\n","- Média igual a 0\n","- Desvio padrão igual a 1\n","\n","A normalização é essencial para redes neurais, pois:\n","- Evita que features em escalas maiores dominem o treinamento\n","- Facilita a convergência do otimizador"],"metadata":{"id":"lcKnMJYSl76G"}},{"cell_type":"code","source":["scaler = StandardScaler()\n","X = scaler.fit_transform(X)"],"metadata":{"id":"dfzoM0BEgPSn","executionInfo":{"status":"ok","timestamp":1769002573522,"user_tz":180,"elapsed":24,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Split de Treino e Teste\n","\n","Nesta célula dividimos os dados em:\n","- **80% para treinamento**\n","- **20% para teste**\n","\n","O conjunto de teste será utilizado apenas na etapa final para avaliar\n","a capacidade de generalização do modelo."],"metadata":{"id":"eF-0nDaMl98U"}},{"cell_type":"code","source":["X_train, X_test = train_test_split(\n","    X, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"F_l--0iRmkZX","executionInfo":{"status":"ok","timestamp":1769002578782,"user_tz":180,"elapsed":3,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Conversão para Tensores\n","\n","Aqui convertemos os arrays NumPy para tensores do PyTorch.\n","\n","Isso é necessário porque:\n","- O PyTorch opera exclusivamente com tensores\n","- Permite cálculo automático de gradientes (autograd)"],"metadata":{"id":"Bkd6BIKGmFPd"}},{"cell_type":"code","source":["X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test  = torch.tensor(X_test, dtype=torch.float32)"],"metadata":{"id":"qNNjIg5pgQ4O","executionInfo":{"status":"ok","timestamp":1769002597685,"user_tz":180,"elapsed":2,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Definição do Modelo VAE\n","\n","Nesta célula definimos a arquitetura do **Variational Autoencoder**.\n","\n","O VAE é composto por:\n","- **Encoder**: comprime os dados de entrada em um espaço latente\n","- **Espaço Latente**: representado por média (`μ`) e variância (`σ²`)\n","- **Decoder**: reconstrói os dados originais a partir do espaço latente\n","\n","Esse tipo de modelo é amplamente utilizado em:\n","- Aprendizado de representações\n","- Geração de moléculas\n","- Drug Discovery"],"metadata":{"id":"CebOECpNmKfZ"}},{"cell_type":"code","source":["class VAE(nn.Module):\n","    def __init__(self, input_dim, latent_dim):\n","        super().__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 16),\n","            nn.ReLU()\n","        )\n","\n","        self.mu_layer     = nn.Linear(16, latent_dim)\n","        self.logvar_layer = nn.Linear(16, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, input_dim)\n","        )\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def forward(self, x):\n","        h = self.encoder(x)\n","        mu = self.mu_layer(h)\n","        logvar = self.logvar_layer(h)\n","        z = self.reparameterize(mu, logvar)\n","        x_recon = self.decoder(z)\n","        return x_recon, mu, logvar"],"metadata":{"id":"bqpPzQfqgSnk","executionInfo":{"status":"ok","timestamp":1769003357779,"user_tz":180,"elapsed":16,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Função de Perda do VAE\n","\n","A função de perda do VAE possui dois componentes:\n","\n","1. **Erro de Reconstrução (MSE)**  \n","   Mede o quão bem o modelo reconstrói os dados originais.\n","\n","2. **Divergência KL**  \n","   Regulariza o espaço latente para que siga uma distribuição normal padrão.\n","\n","Essa combinação garante:\n","- Boa reconstrução\n","- Espaço latente contínuo e bem estruturado"],"metadata":{"id":"Gw-F4kLemUjy"}},{"cell_type":"code","source":["def vae_loss(recon_x, x, mu, logvar):\n","    recon_loss = nn.MSELoss()(recon_x, x)\n","\n","    kl_div = -0.5 * torch.mean(\n","        1 + logvar - mu.pow(2) - logvar.exp()\n","    )\n","\n","    return recon_loss + kl_div"],"metadata":{"id":"H8qP0APEgULa","executionInfo":{"status":"ok","timestamp":1769003409729,"user_tz":180,"elapsed":6,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Inicialização do Modelo\n","\n","Aqui definimos:\n","- Dimensão de entrada: número de features químicas\n","- Dimensão do espaço latente: 2 (para facilitar visualização)\n","\n","Também inicializamos:\n","- O modelo VAE\n","- O otimizador Adam"],"metadata":{"id":"XaJNvAKPmXgb"}},{"cell_type":"code","source":["input_dim = X_train.shape[1]\n","latent_dim = 2  # espaço latente 2D para visualização\n","\n","model = VAE(input_dim, latent_dim)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","epochs = 200"],"metadata":{"id":"uLb0k9afmgsb","executionInfo":{"status":"ok","timestamp":1769003434195,"user_tz":180,"elapsed":5784,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Treinamento do VAE\n","\n","Nesta célula realizamos o treinamento do modelo.\n","\n","Para cada época:\n","1. O modelo entra em modo de treinamento\n","2. Calcula a reconstrução e a loss\n","3. Executa backpropagation\n","4. Atualiza os pesos\n","\n","A loss impressa reflete:\n","- Qualidade da reconstrução\n","- Organização do espaço latente"],"metadata":{"id":"uj2xJmO-mb7k"}},{"cell_type":"code","source":["for epoch in range(epochs):\n","    model.train()\n","\n","    optimizer.zero_grad()\n","    x_recon, mu, logvar = model(X_train)\n","    loss = vae_loss(x_recon, X_train, mu, logvar)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 20 == 0:\n","        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNLcX7HmgVrk","executionInfo":{"status":"ok","timestamp":1769003469177,"user_tz":180,"elapsed":820,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"befeb544-14ed-4127-ba36-375554536b04"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 000 | Loss: 1.0335\n","Epoch 020 | Loss: 0.9883\n","Epoch 040 | Loss: 0.9797\n","Epoch 060 | Loss: 0.9765\n","Epoch 080 | Loss: 0.9767\n","Epoch 100 | Loss: 0.9743\n","Epoch 120 | Loss: 0.9732\n","Epoch 140 | Loss: 0.9717\n","Epoch 160 | Loss: 0.9737\n","Epoch 180 | Loss: 0.9464\n"]}]},{"cell_type":"markdown","source":["## Avaliação no Conjunto de Teste\n","\n","Aqui avaliamos o desempenho do modelo em dados nunca vistos.\n","\n","- `model.eval()` desativa comportamentos específicos de treino\n","- `torch.no_grad()` evita o cálculo de gradientes\n","\n","Isso nos dá uma estimativa realista da generalização do modelo."],"metadata":{"id":"cVPeQyUpmpKI"}},{"cell_type":"code","source":["model.eval()\n","\n","with torch.no_grad():\n","    x_recon, mu_test, logvar_test = model(X_test)\n","    test_loss = vae_loss(x_recon, X_test, mu_test, logvar_test)\n","\n","print(\"Test Loss:\", round(test_loss.item(), 4))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sqx4-E3AgXTf","executionInfo":{"status":"ok","timestamp":1769003541713,"user_tz":180,"elapsed":20,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"4e524ade-de6f-4d36-f314-a6f8f14fcb5c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 1.0664\n"]}]},{"cell_type":"markdown","source":["## Extração dos Embeddings Latentes\n","\n","Nesta etapa extraímos apenas o vetor de média (`μ`) do espaço latente\n","para todas as moléculas do dataset.\n","\n","Esses embeddings podem ser usados para:\n","- Visualização\n","- Clusterização de moléculas\n","- Similaridade molecular\n","- Geração de novos compostos (Drug Discovery)"],"metadata":{"id":"j7KUDqtVmqzJ"}},{"cell_type":"code","source":["model.eval()\n","\n","with torch.no_grad():\n","    _, mu_all, _ = model(torch.tensor(X, dtype=torch.float32))\n","\n","latent_embeddings = mu_all.numpy()"],"metadata":{"id":"FcZirUAJgZr0","executionInfo":{"status":"ok","timestamp":1769003604952,"user_tz":180,"elapsed":6,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["latent_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7BVNyZImz5X","executionInfo":{"status":"ok","timestamp":1769003613697,"user_tz":180,"elapsed":24,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"28c4a8fc-2627-4561-b477-3de97c069939"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.95040095,  3.063143  ],\n","       [ 0.04440671,  0.0448938 ],\n","       [-0.1410132 , -0.37670258],\n","       ...,\n","       [-0.08523327, -0.21272291],\n","       [-0.2755366 , -0.574624  ],\n","       [ 0.08835062,  0.17385277]], dtype=float32)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"O8uga633gzE8"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"5jAq1PV1gcAS","executionInfo":{"status":"ok","timestamp":1769003714744,"user_tz":180,"elapsed":37,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Representação Molecular com SMILES\n","\n","Nesta etapa, utilizamos a representação **SMILES (Simplified Molecular Input Line Entry System)** para descrever moléculas como sequências de caracteres.\n","\n","Diferentemente dos descritores tabulares, SMILES preserva a **estrutura química explícita**, permitindo que o modelo aprenda padrões diretamente da linguagem molecular.\n","\n","\n","## Tokenização dos SMILES\n","\n","Como redes neurais não operam diretamente sobre texto, os SMILES são **tokenizados**, ou seja, cada caractere químico é convertido em um símbolo discreto.\n","\n","Cada token é mapeado para um índice numérico, criando um vocabulário químico que será usado pela rede neural.\n","\n","## Codificação e Padding das Sequências\n","\n","Os SMILES possuem comprimentos variáveis.  \n","Para permitir o processamento em batch, todas as sequências são:\n","\n","- convertidas para índices numéricos\n","- preenchidas (*padding*) até um comprimento máximo comum\n","\n","O token `<PAD>` é utilizado apenas para alinhamento e não carrega informação química."],"metadata":{"id":"Bvi1PpIWjlst"}},{"cell_type":"code","source":["def tokenize_smiles(smiles):\n","    return list(smiles)\n","\n","smiles_list = df[\"smiles\"].tolist()\n","\n","tokens = sorted(set(\"\".join(smiles_list)))\n","token2idx = {t: i+1 for i, t in enumerate(tokens)}\n","token2idx[\"<PAD>\"] = 0\n","idx2token = {i: t for t, i in token2idx.items()}"],"metadata":{"id":"Ns7IFWuCg1Bn","executionInfo":{"status":"ok","timestamp":1769003928813,"user_tz":180,"elapsed":7,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["max_len = max(len(s) for s in smiles_list)\n","\n","def encode_smiles(smiles):\n","    seq = [token2idx[t] for t in tokenize_smiles(smiles)]\n","    return seq + [0] * (max_len - len(seq))\n","\n","X_smiles = torch.tensor([encode_smiles(s) for s in smiles_list])"],"metadata":{"id":"jPCGeJ8vg5Er","executionInfo":{"status":"ok","timestamp":1769004026273,"user_tz":180,"elapsed":26,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["X_smiles.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VZI_B-i21Vy","executionInfo":{"status":"ok","timestamp":1769004129810,"user_tz":180,"elapsed":35,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"02ef1da4-9212-469f-ae1f-ff8df6c012f0"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1128, 98])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["X_smiles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3P5JkXU3TcF","executionInfo":{"status":"ok","timestamp":1769004156790,"user_tz":180,"elapsed":36,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"e0cb0df1-6003-4900-c766-daa78e757474"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[21, 16, 16,  ...,  0,  0,  0],\n","        [16, 27,  6,  ...,  0,  0,  0],\n","        [16, 16,  3,  ...,  0,  0,  0],\n","        ...,\n","        [16, 16, 23,  ...,  0,  0,  0],\n","        [16, 16, 16,  ...,  0,  0,  0],\n","        [16, 21, 22,  ...,  0,  0,  0]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## Arquitetura do Variational Autoencoder (VAE)\n","\n","Aqui definimos a arquitetura do **SMILES-VAE**, composta por:\n","\n","- **Encoder sequencial:** aprende uma representação compacta da molécula\n","- **Camadas de média (μ) e variância (log σ²):** definem a distribuição latente\n","- **Decoder sequencial:** reconstrói o SMILES a partir do espaço latente\n","\n","Essa arquitetura permite aprender um **espaço latente contínuo e regularizado** para moléculas químicas.\n","\n","## Reparametrização do Espaço Latente\n","\n","O VAE utiliza o truque de **reparametrização** para permitir o treinamento via backpropagation.\n","\n","Em vez de amostrar diretamente da distribuição, o modelo aprende:\n","- a média (μ)\n","- a variância (σ²)\n","\n","e gera o vetor latente de forma diferenciável."],"metadata":{"id":"rFdicZ57jq0G"}},{"cell_type":"code","source":["class SmilesVAE(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, latent_dim):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n","\n","        self.encoder_rnn = nn.GRU(embed_dim, 128, batch_first=True)\n","        self.mu = nn.Linear(128, latent_dim)\n","        self.logvar = nn.Linear(128, latent_dim)\n","\n","        self.decoder_rnn = nn.GRU(embed_dim, 128, batch_first=True)\n","        self.decoder_out = nn.Linear(128, vocab_size)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def forward(self, x):\n","        emb = self.embedding(x)\n","        _, h = self.encoder_rnn(emb)\n","        h = h.squeeze(0)\n","\n","        mu = self.mu(h)\n","        logvar = self.logvar(h)\n","\n","        z = self.reparameterize(mu, logvar)\n","        z = z.unsqueeze(1).repeat(1, x.size(1), 1)\n","\n","        dec_out, _ = self.decoder_rnn(z)\n","        logits = self.decoder_out(dec_out)\n","\n","        return logits, mu, logvar"],"metadata":{"id":"FPUn1Kdpg8AM","executionInfo":{"status":"ok","timestamp":1769004425424,"user_tz":180,"elapsed":41,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Função de Perda do VAE\n","\n","A função de perda do Variational Autoencoder possui dois componentes:\n","\n","1. **Perda de reconstrução:**  \n","   Mede o quão bem o SMILES original é reconstruído pelo decoder.\n","\n","2. **Divergência KL:**  \n","   Regulariza o espaço latente para se aproximar de uma distribuição normal.\n","\n","Essa combinação garante um espaço latente:\n","- contínuo\n","- suave\n","- adequado para geração de novas moléculas\n"],"metadata":{"id":"5eSIqx6ej2nI"}},{"cell_type":"code","source":["def vae_loss(logits, x, mu, logvar):\n","    recon = nn.CrossEntropyLoss(ignore_index=0)(\n","        logits.view(-1, logits.size(-1)),\n","        x.view(-1)\n","    )\n","\n","    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n","    return recon + kl"],"metadata":{"id":"84pi3851g9rY","executionInfo":{"status":"ok","timestamp":1769004433523,"user_tz":180,"elapsed":2,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Treinamento do SMILES-VAE\n","\n","Durante o treinamento, o modelo aprende simultaneamente:\n","- a reconstruir SMILES válidos\n","- a organizar o espaço latente químico\n","\n","O processo ajusta os parâmetros do encoder e decoder para minimizar a perda total do VAE.\n","\n","## Extração de Embeddings Moleculares\n","\n","Após o treinamento, utilizamos apenas o **encoder** para extrair os vetores latentes (μ).\n","\n","Esses vetores representam **embeddings moleculares contínuos**, que podem ser usados para:\n","- clustering químico\n","- busca de moléculas similares\n","- regressão de propriedades\n","- geração de novos candidatos a fármacos\n"],"metadata":{"id":"2U05GfLmj4o-"}},{"cell_type":"code","source":["model = SmilesVAE(\n","    vocab_size=len(token2idx),\n","    embed_dim=32,\n","    latent_dim=32\n",")\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    logits, mu, logvar = model(X_smiles)\n","    loss = vae_loss(logits, X_smiles, mu, logvar)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch} | Loss {loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5OkPWq_g_MN","executionInfo":{"status":"ok","timestamp":1769004777790,"user_tz":180,"elapsed":341634,"user":{"displayName":"Danilo Tertuliano","userId":"14437674909418101195"}},"outputId":"9f3a15a5-6cb8-4c7f-dcc5-d986525ddec7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss 3.4992\n","Epoch 10 | Loss 3.1679\n","Epoch 20 | Loss 2.5440\n","Epoch 30 | Loss 2.4811\n","Epoch 40 | Loss 2.4259\n","Epoch 50 | Loss 2.4102\n","Epoch 60 | Loss 2.4018\n","Epoch 70 | Loss 2.3820\n","Epoch 80 | Loss 2.3773\n","Epoch 90 | Loss 2.3638\n"]}]},{"cell_type":"markdown","source":["## Conexão com Drug Discovery\n","\n","O espaço latente aprendido pelo SMILES-VAE permite aplicações diretas em Drug Discovery, como:\n","\n","- geração de novas moléculas\n","- otimização de propriedades (ADMET, solubilidade, afinidade)\n","- exploração química guiada por aprendizado profundo\n","\n","Essa abordagem está na base de pipelines modernos de descoberta de fármacos baseados em IA.\n"],"metadata":{"id":"uxpRDHiFj99l"}}]}